version: '3.7'
services:

  spacyapi:
    image: jgontrum/spacyapi:all_v2
    hostname: spacyapi
    domainname: pontus-demo-com
    restart: on-failure
    #container_name: spacyapi.pontus-demo-com
    networks:
      pontusvision:
        ipv4_address: 172.28.1.1



#  elasticsearch:
#    image: "elasticsearch:6.7.2"
#    domainname: pontus-demo-com
#    ports:
#      - "9200:9200"
#      - "9300:9300"
#    restart: on-failure
#    privileged: false
#    hostname: elasticsearch
#    container_name: elasticsearch.pontus-demo-com
#    environment:
#      - node.name=elasticsearch
#      - discovery.type=single-node
#      - cluster.name=docker-cluster
#      - "ES_JAVA_OPTS=-Xms2048m -Xmx2048m"
#    networks:
#      pontusvision:
#        ipv4_address: 172.28.1.2
#    ulimits:
#      memlock:
#        soft: -1
#        hard: -1
#

  graphdb-nifi:
    image: "pontusvisiongdpr/pontus-track-graphdb-odb-pt:latest"
    domainname: pontus-demo-com
    ports:
      - "8182:8183"
      - "8183:8183"
      - "7000:7000"
      - "3001:3001"
      - "2480:2480"
      - "5009:5007"
    restart: on-failure
    privileged: false
    hostname: graphdb-nifi
    #container_name: graphdb-nifi.pontus-demo-com
    env_file:
      - secrets/pontus-graphdb
    
    secrets:
      - mapping-salesforce-graph
    #depends_on:
      #- elasticsearch
    networks:
      pontusvision:
        ipv4_address: 172.28.1.3
    command: >
      /bin/bash -c "
        #echo Waiting for elasticsearch service start...;
        #while ! nc -z elasticsearch 9200;
        #do
          #sleep 1;
        #done;
        echo Connected!;
        LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/tmp /orientdb/bin/server.sh 
      "



  pontus-nifi:
    image: "pontusvisiongdpr/pontus-extract-nifi:latest"
    domainname: pontus-demo-com
    ports:
      - "8080:8080"
      - "5006:5006"
      - "5007:5007"
    restart: on-failure
    privileged: false
    hostname: pontus-nifi
    #container_name: pontus-nifi.pontus-demo-com
    secrets:
      - salesforce-client-id
      - salesforce-client-secret
      - salesforce-username
      - salesforce-password
      - office-365-auth-client-secret
      - office-365-auth-client-id
      - office-365-auth-tenant-id
      - watson-user-name
      - watson-password
      - google-creds-json

    volumes:
      - "./nifi-nlp:/var/run/nifi-nlp"


    depends_on:
      - pontus-postgrest
      - graphdb-nifi
      #- mysql
      - spacyapi
    networks:
      pontusvision:
        ipv4_address: 172.28.1.4
    entrypoint: >
      /bin/bash -c "
        getent hosts spacyapi
        echo Waiting for graphdb-nifi service start...;
        while [[ `/usr/bin/curl -s  -H 'Content-Type: application/json' -X POST -d '' http://graphdb-nifi:3001/home/vertex_labels` != *Object.Data_Source* ]] ; do
          sleep 1;
          echo waiting for graph to be ready ... got $$(/usr/bin/curl -s  -H 'Content-Type: application/json' -X POST -d '' http://graphdb-nifi:3001/home/vertex_labels);
        done;
        export RES=$$(/usr/bin/curl -s  -H 'Content-Type: application/json' -X POST -d '' http://graphdb-nifi:3001/home/vertex_labels);
        echo Waiting for vertex_labels... got this: $$RES;
        echo Connected!;
        ../scripts/start.sh
      "


  pontus-formio-mongodb:
    image: "pontusvisiongdpr/pontus-lgpd-formio-mongodb:latest"
    domainname: pontus-demo-com
    ports:
      - "27017:27017"
    restart: on-failure
    privileged: false
    hostname: pontus-formio-mongodb
    #container_name: pontus-formio-mongodb.pontus-demo-com
    command: >
      /bin/bash -c "
        docker-entrypoint.sh mongod &
        if [[ ! -f /data/db/pv-init ]]; then
          sleep 5 
          mongorestore /mongodb  
          sleep 5 
          touch /data/db/pv-init
        fi
        wait %1
      "
    networks:
      pontusvision:
        ipv4_address: 172.28.1.5



  pontus-formio:
    image: "pontusvisiongdpr/pontus-lgpd-formio:latest"
    domainname: pontus-demo-com
    ports:
      - "3005:3005"
      - "8085:8085"
    restart: on-failure
    privileged: true
    hostname: pontus-formio
    #container_name: pontus-formio.pontus-demo-com
    depends_on:
      - pontus-formio-mongodb
    command: >
      /bin/bash -c "
        echo Waiting for mongodb service start...;
        while ! nc -z pontus-formio-mongodb 27017;
        do
          sleep 1;
        done;
        sleep 10;
        echo Connected!;
        /opt/pontus/pontus-formio/current/bin/run-gui.sh
        #while [[ true ]]; do sleep 1; done
      "
    networks:
      pontusvision:
        ipv4_address: 172.28.1.6



  pontus-comply-keycloak:
    image: "pontusvisiongdpr/pontus-comply-keycloak:latest"
    domainname: pontus-demo-com
    hostname: pontus-comply-keycloak
    #container_name: pontus-comply-keycloak.pontus-demo-com
    ports:
      - "5005:8080"
    restart: on-failure
    privileged: true
    networks:
      pontusvision:
        ipv4_address: 172.28.1.7



  pontus-extract-discovery-backend:
    image: "pontusvisiongdpr/pontus-extract-discovery-backend"
    domainname: pontus-demo-com
    hostname: pontus-extract-discovery-backend
    #container_name: pontus-extract-discovery-backend.pontus-demo-com
    ports:
      - "8888:8888"
      - "5008:5008"
    restart: on-failure
    privileged: true
    networks:
      - pontusvision

    depends_on:
      - pontus-extract-discovery-dataset
      - pontus-extract-discovery-transformation
      - pontus-extract-discovery-preparation

    command: >
      /bin/bash -c "
         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/datasets/metadata 
         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/preparations
         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/users
         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/folders
         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/upgrade
         getent hosts pontus-extract-discovery-dataset
         getent hosts pontus-extract-discovery-transformation
         getent hosts pontus-extract-discovery-preparation
         echo Waiting for pontus-nifi service start just to reduce the number of JVMs starting at once...;
         while ! nc -z pontus-nifi 8080;
         do
           sleep 1;
         done;
         java  -Dserver.port=8888  -Dspring.profiles.active=standalone -Dspring.mvc.favicon.enabled=false -Dserver.compression.enabled=true -Dserver.compression.mime-types=text/plain,application/json -Dspring.mvc.async.request-timeout=300000 -Dservice.documentation=false -Dservice.documentation.name='Talend Data Preparation - API' -Dservice.documentation.description='This service exposes high level services that may involve services orchestration.' -Dservice.paths=api -Ddataset.records.limit=30000 -Ddataset.local.file.size.limit=2000000000 -Ddataset.list.limit=10 -Ddataset.imports=local -Ddataset.service.url=http://pontus-extract-discovery-dataset:8288/ -Dtransformation.service.url=http://pontus-extract-discovery-transformation:8388/ -Dpreparation.service.url=http://pontus-extract-discovery-preparation:8188/ -Ddataset.metadata.store=file -Dpreparation.store=file -Duser.data.store=file -Dfolder.store=file -Dupgrade.store=file -Ddataset.metadata.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/datasets/metadata/ -Dpreparation.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/preparations/ -Duser.data.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/users/ -Dfolder.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/folders/ -Dupgrade.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/upgrade -Dcontent-service.store=local -Dcontent-service.store.local.path=/tmp/AppData/Roaming/Talend/dataprep/ -Dpreparation.store.remove.hours=24 -DluceneIndexStrategy=singleton -Ddataquality.indexes.file.location=/tmp/AppData/Roaming/Talend/dataprep/data-quality/2.5.1/org.talend.dataquality.semantic -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5008 -jar /opt/pontus-extract/discovery/lib/dataprep-api.jar
      "
  

  pontus-extract-discovery-transformation:
    image: "pontusvisiongdpr/pontus-extract-discovery-backend"
    domainname: pontus-demo-com
    hostname: pontus-extract-discovery-transformation
    #container_name: pontus-extract-discovery-transformation.pontus-demo-com
    restart: on-failure
    privileged: true
    networks:
      - pontusvision

    command: >
      /bin/bash -c "
         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/datasets/metadata 
         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/preparations
         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/users
         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/folders
         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/upgrade
         echo Waiting for pontus-nifi service start just to reduce the number of JVMs starting at once...;
         while ! nc -z pontus-nifi 8080;
         do
           sleep 1;
         done;
         java  -Dserver.port=8388  -Dspring.profiles.active=standalone -Dspring.mvc.favicon.enabled=false -Dserver.compression.enabled=true -Dserver.compression.mime-types=text/plain,application/json -Dspring.mvc.async.request-timeout=300000 -Dservice.documentation=false -Dservice.documentation.name='Talend Data Preparation - API' -Dservice.documentation.description='This service exposes high level services that may involve services orchestration.' -Dservice.paths=api -Ddataset.records.limit=30000 -Ddataset.local.file.size.limit=2000000000 -Ddataset.list.limit=10 -Ddataset.imports=local -Ddataset.service.url=http://pontus-extract-discovery-dataset:8288/ -Dtransformation.service.url=http://pontus-extract-discovery-transformation:8388/ -Dpreparation.service.url=http://pontus-extract-discovery-preparation:8188/ -Ddataset.metadata.store=file -Dpreparation.store=file -Duser.data.store=file -Dfolder.store=file -Dupgrade.store=file -Ddataset.metadata.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/datasets/metadata/ -Dpreparation.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/preparations/ -Duser.data.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/users/ -Dfolder.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/folders/ -Dupgrade.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/upgrade -Dcontent-service.store=local -Dcontent-service.store.local.path=/tmp/AppData/Roaming/Talend/dataprep/ -Dpreparation.store.remove.hours=24 -DluceneIndexStrategy=singleton -Ddataquality.indexes.file.location=/tmp/AppData/Roaming/Talend/dataprep/data-quality/2.5.1/org.talend.dataquality.semantic -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5008 -jar /opt/pontus-extract/discovery/lib/dataprep-transformation.jar
      "
  

  pontus-extract-discovery-dataset:
    image: "pontusvisiongdpr/pontus-extract-discovery-backend"
    domainname: pontus-demo-com
    hostname: pontus-extract-discovery-dataset
    #container_name: pontus-extract-discovery-dataset.pontus-demo-com
    restart: on-failure
    privileged: true
    ports: 
      - "8288:8288"
    networks:
      - pontusvision

    command: >
      /bin/bash -c "
         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/datasets/metadata 
         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/preparations
         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/users
         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/folders
         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/upgrade
         echo Waiting for pontus-nifi service start just to reduce the number of JVMs starting at once...;
         while ! nc -z pontus-nifi 8080;
         do
           sleep 1;
         done;
         java  -Dserver.port=8288  -Dspring.profiles.active=standalone -Dspring.mvc.favicon.enabled=false -Dserver.compression.enabled=true -Dserver.compression.mime-types=text/plain,application/json -Dspring.mvc.async.request-timeout=300000 -Dservice.documentation=false -Dservice.documentation.name='Talend Data Preparation - API' -Dservice.documentation.description='This service exposes high level services that may involve services orchestration.' -Dservice.paths=api -Ddataset.records.limit=30000 -Ddataset.local.file.size.limit=2000000000 -Ddataset.list.limit=10 -Ddataset.imports=local -Ddataset.service.url=http://pontus-extract-discovery-dataset:8288/ -Dtransformation.service.url=http://pontus-extract-discovery-transformation:8388/ -Dpreparation.service.url=http://pontus-extract-discovery-preparation:8188/ -Ddataset.metadata.store=file -Dpreparation.store=file -Duser.data.store=file -Dfolder.store=file -Dupgrade.store=file -Ddataset.metadata.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/datasets/metadata/ -Dpreparation.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/preparations/ -Duser.data.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/users/ -Dfolder.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/folders/ -Dupgrade.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/upgrade -Dcontent-service.store=local -Dcontent-service.store.local.path=/tmp/AppData/Roaming/Talend/dataprep/ -Dpreparation.store.remove.hours=24 -DluceneIndexStrategy=singleton -Ddataquality.indexes.file.location=/tmp/AppData/Roaming/Talend/dataprep/data-quality/2.5.1/org.talend.dataquality.semantic -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5008 -jar /opt/pontus-extract/discovery/lib/dataprep-dataset.jar
      "
  

  pontus-extract-discovery-preparation:
    image: "pontusvisiongdpr/pontus-extract-discovery-backend"
    domainname: pontus-demo-com
    hostname: pontus-extract-discovery-preparation
    #container_name: pontus-extract-discovery-preparation.pontus-demo-com
    restart: on-failure
    privileged: true
    networks:
      - pontusvision

    command: >
      /bin/bash -c "
         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/datasets/metadata 
         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/preparations
         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/users
         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/folders
         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/upgrade
         echo Waiting for pontus-nifi service start just to reduce the number of JVMs starting at once...;
         while ! nc -z pontus-nifi 8080;
         do
           sleep 1;
         done;
         java  -Dserver.port=8188  -Dspring.profiles.active=standalone -Dspring.mvc.favicon.enabled=false -Dserver.compression.enabled=true -Dserver.compression.mime-types=text/plain,application/json -Dspring.mvc.async.request-timeout=300000 -Dservice.documentation=false -Dservice.documentation.name='Talend Data Preparation - API' -Dservice.documentation.description='This service exposes high level services that may involve services orchestration.' -Dservice.paths=api -Ddataset.records.limit=30000 -Ddataset.local.file.size.limit=2000000000 -Ddataset.list.limit=10 -Ddataset.imports=local -Ddataset.service.url=http://pontus-extract-discovery-dataset:8288/ -Dtransformation.service.url=http://pontus-extract-discovery-transformation:8388/ -Dpreparation.service.url=http://pontus-extract-discovery-preparation:8188/ -Ddataset.metadata.store=file -Dpreparation.store=file -Duser.data.store=file -Dfolder.store=file -Dupgrade.store=file -Ddataset.metadata.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/datasets/metadata/ -Dpreparation.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/preparations/ -Duser.data.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/users/ -Dfolder.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/folders/ -Dupgrade.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/upgrade -Dcontent-service.store=local -Dcontent-service.store.local.path=/tmp/AppData/Roaming/Talend/dataprep/ -Dpreparation.store.remove.hours=24 -DluceneIndexStrategy=singleton -Ddataquality.indexes.file.location=/tmp/AppData/Roaming/Talend/dataprep/data-quality/2.5.1/org.talend.dataquality.semantic -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5008 -jar /opt/pontus-extract/discovery/lib/dataprep-preparation.jar
      " 


  pontus-lgpd:
    image: "pontusvisiongdpr/pontus-comply-nginx-lgpd:latest"
    domainname: pontus-demo-com
    ports:
      - "18443:18443"
    restart: on-failure
    privileged: true
    hostname: pontus-lgpd
    #container_name: pontus-lgpd.pontus-demo-com
    networks:
      pontusvision:
        ipv4_address: 172.28.1.11
    depends_on:
      - pontus-formio-mongodb
      - pontus-formio
      - pontus-nifi
      - pontus-comply-keycloak
      # - pontus-extract-discovery-backend

    command: >
      /bin/bash -c "
         getent hosts pontus-formio.pontus-demo-com
         getent hosts pontus-nifi.pontus-demo-com
         getent hosts pontus-comply-keycloak.pontus-demo-com
         echo Waiting for pontus-nifi service start just to reduce the number of JVMs starting at once...;
         nginx -g 'daemon off;'
      "

  pontus-timescaledb:
    image: "pontusvisiongdpr/timescaledb:latest"
    domainname: pontus-demo-com
    restart: on-failure
    hostname: pontus-timescaledb
    #container_name: pontus-timescaledb.pontus-demo-com
    networks:
      pontusvision:
        ipv4_address: 172.28.1.12
    env_file:
      - secrets/pontus-timescaledb


  pontus-grafana:
    image: "pontusvisiongdpr/grafana:latest"
    domainname: pontus-demo-com
    restart: on-failure
    hostname: pontus-grafana
    #container_name: pontus-grafana.pontus-demo-com
    depends_on:
      - pontus-timescaledb
      - pontus-lgpd

    networks:
      pontusvision:
        ipv4_address: 172.28.1.13
    env_file:
      - secrets/pontus-grafana
    entrypoint: >
      bash -c "
        getent hosts pontus-lgpd &&
        # we need to do this hack to redirect localhost:18443 to the pontus-lgpd gateway to get
        # the JWT token.
        while nc -l -p 18443 -k -c 'nc pontus-lgpd 18443' || true; do true; done &
        /run.sh

      "


  pontus-postgrest:
    image: "pontusvisiongdpr/postgrest:latest"
    domainname: pontus-demo-com
    restart: on-failure
    hostname: pontus-postgrest
    #container_name: pontus-postgrest.pontus-demo-com
    depends_on:
      - pontus-timescaledb

    networks:
      pontusvision:
        ipv4_address: 172.28.1.14
    env_file:
      - secrets/pontus-postgrest

#  mysql:
#    build: ./mysql
#    hostname: mysql
#    domainname: pontus-demo-com
#    container_name: mysql.pontus-demo-com
#  #  command: --default-authentication-plugin=mysql_native_password
#    restart: always
#    privileged: true
#    environment:
##      MYSQL_DATABASE: jwdb 
#      MYSQL_DATABASE: employees 
#      MYSQL_PORT: 3306 
#      MYSQL_USER: joget
#      MYSQL_PASSWORD: joget
#      MYSQL_ROOT_PASSWORD: jwdb
#    healthcheck:
#      test: mysqladmin ping -h 127.0.0.1 -u $$MYSQL_USER --password=$$MYSQL_PASSWORD
#      interval: 30s
#      timeout: 10s
#      retries: 5
#
#
#    networks:
#      pontusvision:
#        ipv4_address: 172.28.1.15
#
#  joget:
#    image: jogetworkflow/joget-community
#    hostname: joget
#    domainname: pontus-demo-com
#    container_name: joget.pontus-demo-com
#    depends_on:
#      - mysql
#
#    restart: always
#    ports:
#      - "4000:8080"
#    environment:
#      MYSQL_ROOT_PASSWORD: jwdb
#      MYSQL_HOST: mysql.pontus-demo-com 
#      MYSQL_DATABASE: jwdb 
#      MYSQL_PORT: 3306 
#      MYSQL_USER: joget
#      MYSQL_PASSWORD: joget
#
#    networks:
#      - pontusvision
    




networks:
  pontusvision:
    ipam:
      driver: default
      config:
        - subnet: 172.28.0.0/16


secrets:
  salesforce-client-id:
    file: secrets/salesforce-client-id
  salesforce-client-secret:
    file:  secrets/salesforce-client-secret
  salesforce-username:
    file: secrets/salesforce-username
  salesforce-password:
    file: secrets/salesforce-password
  office-365-auth-client-secret:
    file: secrets/office-365-auth-client-secret
  office-365-auth-client-id:
    file: secrets/office-365-auth-client-id
  office-365-auth-tenant-id:
    file: secrets/office-365-auth-tenant-id
  watson-user-name:
    file: secrets/watson-user-name
  watson-password:
    file: secrets/watson-password
  google-creds-json:
    file: secrets/google-creds-json
  mapping-salesforce-graph:
    file: secrets/mapping-salesforce-graph

